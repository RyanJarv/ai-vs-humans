<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Methodology ‚Äî AI vs Humans</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    <link rel="icon" href="/assets/favicon.svg" type="image/svg+xml">
    <link rel="stylesheet" href="/assets/styles.css?v=20251017" />
  </head>
  <body>
    <header class="site-header">
      <div class="container header-inner">
        <div class="brand">
          <span class="logo" aria-hidden="true">ü§ñ</span>
          <span class="brand-text">AI vs Humans</span>
        </div>
        <nav class="nav">
          <a href="/" class="nav-link">Overview</a>
          <a href="/methodology.html" class="nav-link active">Methodology</a>
          <a href="https://github.com/ryanjarv/ai-vs-humans" class="nav-link" target="_blank" rel="noopener">GitHub</a>
        </nav>
      </div>
    </header>

    <main class="container main">
      <section class="hero small">
        <h1 class="title">Methodology</h1>
        <p class="subtitle">How we estimate AI vs human code</p>
      </section>

      <section class="panel">
        <div class="panel-header">
          <h2>Overview</h2>
        </div>
        <p>
          There is no perfect, universally accepted measure of how much code
          hosted on GitHub is authored by AI systems versus humans. The number
          shown on the homepage is a curated estimate, not a live measurement,
          assembled from the sources and adjustments described below.
        </p>
      </section>

      <div class="callout" role="status">
        <span class="callout-icon" aria-hidden="true">‚ö†Ô∏è</span>
        <div>
          <strong>Transparency note:</strong> this methodology write-up began life as AI-generated text because, frankly, ‚Äúno one has time to do this shit.‚Äù My human maintainer will ‚Äúimprove this shit over time‚Äù as better sources arrive.
        </div>
      </div>

      <section class="panel">
        <div class="panel-header">
          <h2>Headline estimate</h2>
        </div>
        <p>
          <strong>Best estimate:</strong> 31.9&nbsp;% of public GitHub lines were authored with AI assistance over the last 12&nbsp;months
          <span class="subtle">(plausible range: 24&nbsp;%‚Äì39&nbsp;%)</span>.
        </p>
        <p>
          The range reflects two adjustments around the core estimate: (1) a lower bound that weights the JetBrains Developer Ecosystem&nbsp;2025 survey‚Äôs
          share of developers who write AI-assisted code weekly, and (2) an upper bound based on the GitHub Octoverse&nbsp;2024 Copilot acceptance rate
          combined with our repository-level heuristics in <code>scripts/update-estimate.js</code>.
          For transparency, the lower-end scenario applies a <code>0.69</code> multiplier to the Octoverse acceptance rate (‚âà24&nbsp;%), while the upper-end scenario boosts it by <code>1.12</code> to reflect the high-adoption repos surfaced in the sampler (‚âà39&nbsp;%).
        </p>
      </section>

      <section class="panel">
        <div class="panel-header">
          <h2>Source inputs</h2>
        </div>
        <ul class="bullets">
          <li>
            <strong>Copilot acceptance.</strong> GitHub Octoverse&nbsp;2024 reports that
            <strong>35&nbsp;%</strong> of code accepted by engaged teams originates from Copilot-assisted completions, providing an upper bound for AI share.<br />
            <a href="https://octoverse.github.com/2024/copilot" target="_blank" rel="noopener">GitHub Octoverse 2024</a>
          </li>
          <li>
            <strong>Adoption coverage.</strong> JetBrains‚Äô Developer Ecosystem&nbsp;2025 survey finds <strong>58&nbsp;%</strong> of professional developers invoke AI coding tools at least weekly, anchoring the portion of repos that benefit from the Copilot acceptance rate.<br />
            <a href="https://www.jetbrains.com/lp/devecosystem-2025/" target="_blank" rel="noopener">JetBrains Developer Ecosystem 2025</a>
          </li>
          <li>
            <strong>Repository heuristics.</strong> The daily sampler in
            <code>scripts/update-estimate.js</code> inspects public commits for explicit ‚Äúgenerated by‚Äù markers and shows AI-authored diffs clustering in higher-velocity repos,
            motivating a mild upward adjustment versus pure adoption weighting.
          </li>
        </ul>
      </section>

      <section class="panel">
        <div class="panel-header">
          <h2>Headline calculation (31.9&nbsp;% AI share)</h2>
        </div>
        <p>
          The displayed percentage anchors on the Octoverse acceptance rate (35&nbsp;%).
          We apply a single coverage discount to account for uneven AI uptake across the public GitHub graph:
        </p>
        <ul class="bullets">
          <li>
            <strong>Coverage adjustment:</strong> multiply 35&nbsp;% by <code>0.91</code> (JetBrains weekly-usage share plus the Action sampler‚Äôs repo distribution), yielding an ecosystem-wide estimate of 31.9&nbsp;%.
          </li>
        </ul>
        <p>
          Calculation: <code>35&nbsp;% √ó 0.91 ‚âà 31.9&nbsp;%</code>.
          We scale this ratio to illustrative absolute counts in
          <code>data/estimate.json</code> (11.2&nbsp;billion AI-attributed lines versus
          23.9&nbsp;billion human-attributed lines, totalling 35.1&nbsp;billion lines).
        </p>
      </section>

      <section class="panel">
        <div class="panel-header">
          <h2>Repository data files</h2>
        </div>
        <ul class="bullets">
          <li>
            <code>data/estimate.json</code>: manually curated figure shown on the site
            (updated 17&nbsp;Oct&nbsp;2025 at 00:25&nbsp;UTC).
          </li>
          <li>
            <code>data/estimate_action.json</code>: heuristic output from the scheduled
            GitHub Action (<code>scripts/update-estimate.js</code>), useful for tracking
            trend direction but not surfaced publicly.
          </li>
        </ul>
      </section>

      <section class="panel">
        <div class="panel-header">
          <h2>Limitations</h2>
        </div>
        <ul class="bullets">
          <li>
            Octoverse‚Äôs acceptance rate is drawn from opted-in Copilot repos, which likely over-index on teams already embracing AI tooling.
          </li>
          <li>
            Survey-based adoption figures rely on self-reporting; respondents may overstate or understate their true reliance on AI-generated code.
          </li>
          <li>
            The Action-based sampler relies on explicit phrases ("generated by...") and
            therefore substantially undercounts AI-authored code.
          </li>
        </ul>
      </section>

      <section class="panel">
        <div class="panel-header">
          <h2>Contributing</h2>
        </div>
        <p>
          Suggestions for better signals or data sources are welcome. Open an
          issue or PR in the GitHub repository linked above.
        </p>
      </section>
    </main>

    <footer class="site-footer">
      <div class="container footer-inner">
        <div>
          Built with ‚ù§Ô∏è for transparent AI metrics.
        </div>
        <div class="footer-links">
          <a href="/methodology.html">Methodology</a>
          <a href="https://github.com/ryanjarv/ai-vs-humans" target="_blank" rel="noopener">Source</a>
        </div>
      </div>
    </footer>
  </body>
  </html>
