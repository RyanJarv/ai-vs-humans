## AI vs Humans — Code on GitHub

A minimal static site that displays a curated (non-live) estimate of how much code on GitHub is written by AI versus humans.

### Structure

- `index.html` — Overview page with counters and chart
- `methodology.html` — Methodology and limitations
- `assets/styles.css` — Styling
- `assets/app.js` — Fetches and renders `data/estimate.json`
- `data/estimate.json` — Current numbers (update this file)
- `CNAME` and `.nojekyll` — GitHub Pages configuration

### Local development

Serve locally with any static server, e.g.:

```
python3 -m http.server 8080
# then open http://localhost:8080
```

### Updating the data

Edit `data/estimate.json` and push. The UI will automatically render the new values. This file is hand-maintained and should reference the external sources documented in `methodology.html`.

`estimate.json` format:

```json
{
  "updated_at": "2025-10-17T16:00:00Z",
  "scope": "Public GitHub codebase (curated synthesis of external research)",
  "ai_lines": 6200000000,
  "human_lines": 17900000000,
  "notes": "Headline percentage derived from published sources — keep this in sync with methodology"
}
```

### GitHub Pages

Enable Pages in repo settings:
- Source: `main` branch, `/ (root)`
- Custom domain: `ai-vs-humans.ryanjarv.sh` (this repo includes `CNAME`)

### Automation

- A scheduled GitHub Action samples public code via the GitHub API and writes its findings to `data/estimate_action.json`. See `.github/workflows/update-estimate.yml` and `scripts/update-estimate.js`.
  - Use this file to review the heuristic output; the public site still uses `data/estimate.json` (curated manually).
  - Caveat: relies on explicit AI markers (e.g., "generated by ChatGPT/Copilot/Claude"), so it undercounts AI-written code.
  - Current sample covers JavaScript, TypeScript, Python, and Go to keep API usage low.

### Transparency note

- The initial copy and methodology were produced by AI because, in the owner’s words, “no one has time to do this shit.” Expect the human maintainer to “improve this shit over time” as better data appears.

### Roadmap

- Explore better attribution signals and sampling for more robust estimates.
